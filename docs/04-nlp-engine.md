# 4. NLP Engine - Ph√¢n T√≠ch Ng√¥n Ng·ªØ T·ª± Nhi√™n

## üìã M√¥ T·∫£ Nghi·ªáp V·ª•

### V·∫•n ƒë·ªÅ c·∫ßn gi·∫£i quy·∫øt
Trader th∆∞·ªùng ghi ch√∫ khi giao d·ªãch, nh·ªØng ghi ch√∫ n√†y ch·ª©a th√¥ng tin qu√Ω gi√° v·ªÅ:
- **T√¢m tr·∫°ng** l√∫c v√†o l·ªánh (lo l·∫Øng, t·ª± tin, s·ª£ h√£i)
- **L√Ω do** quy·∫øt ƒë·ªãnh (tin t·ª©c, ph√¢n t√≠ch, c·∫£m t√≠nh)
- **K·ª≥ v·ªçng** (target, stop loss, th·ªùi gian hold)

NLP Engine s·∫Ω **t·ª± ƒë·ªông ph√¢n t√≠ch** nh·ªØng ghi ch√∫ n√†y ƒë·ªÉ:
1. X√°c ƒë·ªãnh **sentiment** (t√≠ch c·ª±c/ti√™u c·ª±c)
2. Ph√°t hi·ªán **emotional markers** (FOMO, Greed, Fear)
3. ƒê√°nh gi√° **quality of reasoning** (logic vs c·∫£m t√≠nh)

### V√≠ d·ª• ph√¢n t√≠ch

| Ghi ch√∫ c·ªßa Trader | Ph√¢n t√≠ch NLP |
|-------------------|---------------|
| "BTC breakout, ph·∫£i v√†o ngay k·∫ªo l·ª°!" | üî¥ FOMO detected, Urgency: HIGH |
| "ƒê√£ ph√¢n t√≠ch k·ªπ, RR 1:3, ch·ªù pullback" | üü¢ Rational, Confidence: MEDIUM |
| "Thua 3 l·ªánh r·ªìi, l·ªánh n√†y ph·∫£i g·ª°" | üî¥ REVENGE risk, Desperation: HIGH |
| "Theo trend l·ªõn, size nh·ªè test tr∆∞·ªõc" | üü¢ Disciplined, Risk-aware: HIGH |

### Y√™u c·∫ßu nghi·ªáp v·ª•

| ID | Requirement | M√¥ t·∫£ |
|----|-------------|-------|
| NLP-01 | Bilingual | H·ªó tr·ª£ ti·∫øng Vi·ªát v√† ti·∫øng Anh |
| NLP-02 | Sentiment scoring | Score t·ª´ -1 (bearish) ƒë·∫øn +1 (bullish) |
| NLP-03 | Emotion detection | Ph√°t hi·ªán Fear, Greed, FOMO, Anxiety |
| NLP-04 | Quality scoring | ƒê√°nh gi√° ƒë·ªô rational c·ªßa reasoning |
| NLP-05 | Real-time | Ph√¢n t√≠ch trong <500ms |

---

## üîß X·ª≠ L√Ω K·ªπ Thu·∫≠t

### Ki·∫øn tr√∫c NLP Pipeline

```mermaid
graph TB
    A[Trade Note] --> B[Preprocessor]
    B --> C[Language Detector]
    
    C -->|Vietnamese| D[Vietnamese Tokenizer]
    C -->|English| E[English Tokenizer]
    
    D --> F[FinBERT/VADER]
    E --> F
    
    F --> G[Sentiment Score]
    F --> H[Emotion Classifier]
    F --> I[Keyword Matcher]
    
    G --> J[NLP Result]
    H --> J
    I --> J
```

### Tech Stack

| Component | Technology |
|-----------|------------|
| Sentiment Analysis | FinBERT (ProsusAI/finbert) |
| Fallback Sentiment | VADER (1,600+ keywords) |
| Vietnamese NLP | PhoBERT ho·∫∑c Custom dictionary |
| Tokenization | underthesea (Vietnamese) |
| Inference | HuggingFace Transformers |

### Vietnamese Trading Keywords Dictionary

```python
VIETNAMESE_TRADING_KEYWORDS = {
    # FOMO indicators
    "fomo": {
        "keywords": [
            "s·ª£ l·ª°", "ph·∫£i v√†o ngay", "mua g·∫•p", "kh√¥ng k·ªãp",
            "ƒëang bay", "pump r·ªìi", "fomo", "all in", "ch·ªët li·ªÅn",
            "b·∫Øt ƒë√°y", "ƒëu·ªïi gi√°", "l·ª° t√†u"
        ],
        "weight": -0.8,
        "emotion": "FOMO"
    },
    
    # Fear indicators
    "fear": {
        "keywords": [
            "s·ª£", "lo l·∫Øng", "hoang mang", "panic", "c·∫Øt l·ªó ngay",
            "b√°n th√°o", "dump", "s·∫≠p", "crash", "liquidate"
        ],
        "weight": -0.6,
        "emotion": "FEAR"
    },
    
    # Greed indicators  
    "greed": {
        "keywords": [
            "x10", "x100", "moon", "rich", "gi√†u", "l·ªùi to",
            "all in", "leverage cao", "margin max", "full port"
        ],
        "weight": -0.5,
        "emotion": "GREED"
    },
    
    # Revenge indicators
    "revenge": {
        "keywords": [
            "g·ª° g·∫°c", "g·ª° l·∫°i", "tr·∫£ th√π", "thua ƒë·ªß r·ªìi",
            "ph·∫£i th·∫Øng", "kh√¥ng th·ªÉ thua n·ªØa", "l·∫•y l·∫°i"
        ],
        "weight": -0.9,
        "emotion": "REVENGE"
    },
    
    # Rational indicators (positive)
    "rational": {
        "keywords": [
            "ph√¢n t√≠ch", "theo k·∫ø ho·∫°ch", "RR", "stop loss",
            "take profit", "qu·∫£n l√Ω v·ªën", "size nh·ªè", "test",
            "ch·ªù x√°c nh·∫≠n", "pullback", "retest"
        ],
        "weight": 0.7,
        "emotion": "RATIONAL"
    },
    
    # Confidence indicators
    "confident": {
        "keywords": [
            "ch·∫Øc ch·∫Øn", "tin t∆∞·ªüng", "setup ƒë·∫πp", "high probability",
            "theo trend", "x√°c nh·∫≠n r·ªìi"
        ],
        "weight": 0.5,
        "emotion": "CONFIDENT"
    }
}
```

### Implementation

#### Main NLP Engine
```python
class NLPEngine:
    def __init__(self):
        # Load FinBERT for financial sentiment
        self.finbert = pipeline(
            "sentiment-analysis",
            model="ProsusAI/finbert"
        )
        
        # VADER for backup/speed
        self.vader = SentimentIntensityAnalyzer()
        
        # Custom Vietnamese dictionary
        self.vn_keywords = VIETNAMESE_TRADING_KEYWORDS
    
    def analyze(self, text: str) -> NLPResult:
        # Detect language
        lang = self._detect_language(text)
        
        # Get sentiment score
        sentiment = self._get_sentiment(text, lang)
        
        # Detect emotions
        emotions = self._detect_emotions(text, lang)
        
        # Match behavioral keywords
        behavioral_flags = self._match_keywords(text)
        
        # Calculate quality score
        quality_score = self._assess_quality(text, emotions)
        
        return NLPResult(
            text=text,
            language=lang,
            sentiment_score=sentiment.score,
            sentiment_label=sentiment.label,
            emotions=emotions,
            behavioral_flags=behavioral_flags,
            quality_score=quality_score,
            warnings=self._generate_warnings(behavioral_flags)
        )
    
    def _detect_emotions(self, text: str, lang: str) -> List[Emotion]:
        emotions = []
        text_lower = text.lower()
        
        for category, data in self.vn_keywords.items():
            matched = [kw for kw in data["keywords"] if kw in text_lower]
            if matched:
                emotions.append(Emotion(
                    type=data["emotion"],
                    confidence=min(len(matched) * 0.2, 1.0),
                    matched_keywords=matched
                ))
        
        return emotions
    
    def _assess_quality(self, text: str, emotions: List[Emotion]) -> float:
        """
        ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng reasoning:
        - C√≥ mention risk management? (+)
        - C√≥ plan c·ª• th·ªÉ? (+)
        - C√≥ emotional markers? (-)
        """
        score = 0.5  # Baseline
        
        # Positive indicators
        if any(kw in text.lower() for kw in ["stop loss", "sl", "take profit", "tp"]):
            score += 0.15
        if any(kw in text.lower() for kw in ["rr", "risk reward", "qu·∫£n l√Ω v·ªën"]):
            score += 0.15
        if any(kw in text.lower() for kw in ["k·∫ø ho·∫°ch", "plan", "theo chi·∫øn l∆∞·ª£c"]):
            score += 0.1
        
        # Negative indicators
        for emotion in emotions:
            if emotion.type in ["FOMO", "REVENGE", "GREED"]:
                score -= 0.2 * emotion.confidence
            elif emotion.type == "FEAR":
                score -= 0.1 * emotion.confidence
        
        return max(0, min(1, score))
```

### Output Schema

```python
@dataclass
class NLPResult:
    text: str
    language: str  # "vi" or "en"
    
    # Sentiment
    sentiment_score: float  # -1 to 1
    sentiment_label: str    # "positive", "negative", "neutral"
    
    # Emotions detected
    emotions: List[Emotion]
    
    # Behavioral flags
    behavioral_flags: List[str]  # ["FOMO", "REVENGE", etc.]
    
    # Quality assessment
    quality_score: float  # 0 to 1
    
    # Generated warnings
    warnings: List[str]

@dataclass
class Emotion:
    type: str  # "FOMO", "FEAR", "GREED", "REVENGE", "RATIONAL", "CONFIDENT"
    confidence: float  # 0 to 1
    matched_keywords: List[str]
```

### Performance Optimization

```python
# Batch processing for historical analysis
async def analyze_batch(notes: List[str]) -> List[NLPResult]:
    # Use FinBERT batch inference
    sentiments = self.finbert(notes, batch_size=32)
    
    results = []
    for note, sentiment in zip(notes, sentiments):
        # Keyword matching is fast, run sequentially
        result = self._build_result(note, sentiment)
        results.append(result)
    
    return results

# Caching for repeated analysis
@lru_cache(maxsize=1000)
def analyze_cached(text_hash: str, text: str) -> NLPResult:
    return self.analyze(text)
```

### Implementation Files

| File | Ch·ª©c nƒÉng |
|------|-----------|
| `nlp/nlp_engine.py` | Main NLP analysis engine |
| `nlp/vietnamese_keywords.py` | Vietnamese trading dictionary |
| `nlp/sentiment_analyzer.py` | FinBERT + VADER wrapper |
| `nlp/emotion_detector.py` | Emotion classification |
| `nlp/quality_scorer.py` | Reasoning quality assessment |

### API Endpoints

```python
POST /api/nlp/analyze           # Analyze single text
POST /api/nlp/analyze-batch     # Analyze multiple texts
GET  /api/nlp/keywords          # Get keyword dictionary
POST /api/nlp/feedback          # User feedback for improvement
```
