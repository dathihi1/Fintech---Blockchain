# 1. Kafka Pipeline - Data Ingestion & Streaming

## ğŸ“‹ MÃ´ Táº£ Nghiá»‡p Vá»¥

### Váº¥n Ä‘á» cáº§n giáº£i quyáº¿t
Trader cáº§n má»™t há»‡ thá»‘ng cÃ³ thá»ƒ:
- **Thu tháº­p dá»¯ liá»‡u tá»« nhiá»u nguá»“n**: API sÃ n giao dá»‹ch (Binance, Bybit), nháº­p tay, import file CSV
- **Xá»­ lÃ½ real-time**: Má»—i giao dá»‹ch má»›i cáº§n Ä‘Æ°á»£c phÃ¢n tÃ­ch ngay láº­p tá»©c
- **Äáº£m báº£o khÃ´ng máº¥t dá»¯ liá»‡u**: DÃ¹ há»‡ thá»‘ng cÃ³ sá»± cá»‘, dá»¯ liá»‡u giao dá»‹ch pháº£i Ä‘Æ°á»£c báº£o toÃ n
- **Kháº£ nÄƒng má»Ÿ rá»™ng**: Theo dÃµi Ä‘Æ°á»£c nhiá»u mÃ£ (symbols) cÃ¹ng lÃºc

### Luá»“ng nghiá»‡p vá»¥
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      NGUá»’N Dá»® LIá»†U                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Binance API â”‚ Manual Entry    â”‚ CSV Import                      â”‚
â”‚ Bybit API   â”‚ (User nháº­p tay) â”‚ (Lá»‹ch sá»­ giao dá»‹ch)             â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚               â”‚                         â”‚
       â–¼               â–¼                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    KAFKA TOPICS                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ raw-trades â†’ normalized-trades â†’ enriched-trades â†’ alerts       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### YÃªu cáº§u nghiá»‡p vá»¥ cá»¥ thá»ƒ

| ID | Requirement | MÃ´ táº£ |
|----|-------------|-------|
| KF-01 | Multi-symbol tracking | Theo dÃµi báº¥t ká»³ mÃ£ coin/stock nÃ o user muá»‘n |
| KF-02 | Real-time ingestion | Nháº­n trade má»›i trong < 1 giÃ¢y |
| KF-03 | Data normalization | Chuáº©n hÃ³a format tá»« cÃ¡c sÃ n khÃ¡c nhau |
| KF-04 | Fault tolerance | KhÃ´ng máº¥t data khi service restart |
| KF-05 | Scalability | Xá»­ lÃ½ Ä‘Æ°á»£c 1000+ trades/phÃºt |

---

## ğŸ”§ Xá»­ LÃ½ Ká»¹ Thuáº­t

### Kiáº¿n trÃºc

```mermaid
graph LR
    subgraph Sources
        A[Binance WS]
        B[Bybit API]
        C[Manual Input]
    end
    
    subgraph Kafka
        D[raw-trades]
        E[normalized-trades]
        F[enriched-trades]
    end
    
    subgraph Consumers
        G[Normalizer]
        H[Enricher]
        I[Analyzer]
    end
    
    A --> D
    B --> D
    C --> D
    D --> G --> E
    E --> H --> F
    F --> I
```

### Tech Stack
- **Message Queue**: Apache Kafka 3.x (hoáº·c Redpanda cho lightweight)
- **Producer**: Python + `aiokafka` (async)
- **Consumer**: Python + `faust-streaming` (stream processing)
- **Serialization**: Avro/JSON Schema

### Kafka Topics Design

| Topic | Purpose | Retention |
|-------|---------|-----------|
| `raw-trades` | Giao dá»‹ch thÃ´ tá»« nguá»“n | 7 days |
| `normalized-trades` | ÄÃ£ chuáº©n hÃ³a format | 30 days |
| `enriched-trades` | ÄÃ£ gáº¯n market context | 90 days |
| `behavioral-alerts` | Cáº£nh bÃ¡o hÃ nh vi | 7 days |

### Data Schema (Avro)

```json
{
  "type": "record",
  "name": "Trade",
  "fields": [
    {"name": "trade_id", "type": "string"},
    {"name": "user_id", "type": "string"},
    {"name": "symbol", "type": "string"},
    {"name": "side", "type": {"type": "enum", "symbols": ["BUY", "SELL"]}},
    {"name": "entry_price", "type": "double"},
    {"name": "exit_price", "type": ["null", "double"]},
    {"name": "quantity", "type": "double"},
    {"name": "entry_time", "type": "long"},
    {"name": "exit_time", "type": ["null", "long"]},
    {"name": "pnl", "type": ["null", "double"]},
    {"name": "notes", "type": ["null", "string"]},
    {"name": "source", "type": "string"}
  ]
}
```

### Implementation Files

| File | Chá»©c nÄƒng |
|------|-----------|
| `kafka/producer.py` | Publish trades vÃ o raw-trades topic |
| `kafka/consumer.py` | Consumer groups cho processing |
| `kafka/normalizer.py` | Chuáº©n hÃ³a data tá»« cÃ¡c sÃ n |
| `kafka/schemas.py` | Avro schemas definition |

### API Endpoints liÃªn quan

```python
POST /api/trades                 # Manual trade entry â†’ Kafka
POST /api/trades/import          # CSV import â†’ Kafka
WS   /ws/trades/{user_id}        # WebSocket feed tá»« Kafka
```

### Demo Mode (Hackathon)
Khi khÃ´ng cÃ³ Kafka infrastructure:
```python
# Sá»­ dá»¥ng asyncio.Queue thay tháº¿
from asyncio import Queue
trade_queue = Queue()

# Interface giá»‘ng Kafka producer
async def publish_trade(trade: Trade):
    await trade_queue.put(trade)
```
