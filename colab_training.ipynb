{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üöÄ Smart Trading Journal - Model Training\n",
                "\n",
                "**Notebook n√†y gi√∫p b·∫°n train NLP & Behavioral models tr√™n Google Colab v·ªõi GPU mi·ªÖn ph√≠**\n",
                "\n",
                "## H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng:\n",
                "1. **Upload file n√†y l√™n Google Colab**: V√†o [colab.research.google.com](https://colab.research.google.com), ch·ªçn File > Upload notebook\n",
                "2. **B·∫≠t GPU**: Runtime > Change runtime type > T4 GPU\n",
                "3. **Ch·∫°y t·ª´ng cell** ho·∫∑c Runtime > Run all\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üì¶ B∆∞·ªõc 1: C√†i ƒë·∫∑t dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
                "!pip install -q torch transformers datasets scikit-learn pandas numpy xgboost vaderSentiment langdetect\n",
                "\n",
                "# Ki·ªÉm tra GPU\n",
                "import torch\n",
                "print(f\"‚úÖ PyTorch version: {torch.__version__}\")\n",
                "print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìÇ B∆∞·ªõc 2: Upload project files\n",
                "\n",
                "C√≥ 2 c√°ch:\n",
                "- **C√°ch 1**: Upload file zip (khuy·∫øn ngh·ªã)\n",
                "- **C√°ch 2**: Mount Google Drive"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# C√°ch 1: Upload file zip\n",
                "# B·∫°n c·∫ßn zip th∆∞ m·ª•c backend v√† upload l√™n Colab\n",
                "\n",
                "from google.colab import files\n",
                "import zipfile\n",
                "import os\n",
                "\n",
                "print(\"üì§ Upload file backend.zip t·ª´ m√°y t√≠nh c·ªßa b·∫°n...\")\n",
                "print(\"(Zip th∆∞ m·ª•c 'backend' tr∆∞·ªõc khi upload)\")\n",
                "print()\n",
                "\n",
                "uploaded = files.upload()\n",
                "\n",
                "for filename in uploaded.keys():\n",
                "    if filename.endswith('.zip'):\n",
                "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
                "            zip_ref.extractall('/content/')\n",
                "        print(f\"‚úÖ Extracted: {filename}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# C√°ch 2 (Alternative): Mount Google Drive\n",
                "# Uncomment n·∫øu b·∫°n ƒë√£ upload l√™n Drive\n",
                "\n",
                "# from google.colab import drive\n",
                "# drive.mount('/content/drive')\n",
                "# !cp -r /content/drive/MyDrive/smart-trading-journal/backend /content/"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Th√™m path v√†o sys.path\n",
                "import sys\n",
                "sys.path.insert(0, '/content/backend')\n",
                "\n",
                "# Ki·ªÉm tra c·∫•u tr√∫c\n",
                "!ls -la /content/backend/"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üîß B∆∞·ªõc 3: C·∫•u h√¨nh Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# C·∫•u h√¨nh training\n",
                "CONFIG = {\n",
                "    # NLP Model\n",
                "    \"base_model\": \"ProsusAI/finbert\",  # Ho·∫∑c \"vinai/phobert-base\" cho ti·∫øng Vi·ªát\n",
                "    \"learning_rate\": 2e-5,\n",
                "    \"batch_size\": 16,\n",
                "    \"epochs\": 3,\n",
                "    \"max_length\": 128,\n",
                "    \n",
                "    # Labels\n",
                "    \"sentiment_labels\": [\"negative\", \"neutral\", \"positive\"],\n",
                "    \"emotion_labels\": [\"FOMO\", \"FEAR\", \"GREED\", \"REVENGE\", \"RATIONAL\", \"CONFIDENT\", \"DISCIPLINE\", \"NEUTRAL\"]\n",
                "}\n",
                "\n",
                "print(\"‚úÖ Config loaded\")\n",
                "print(f\"   Base model: {CONFIG['base_model']}\")\n",
                "print(f\"   Epochs: {CONFIG['epochs']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìä B∆∞·ªõc 4: Chu·∫©n b·ªã Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import os\n",
                "\n",
                "# Load dataset\n",
                "dataset_path = \"/content/backend/ml/training/nlp_dataset.json\"\n",
                "\n",
                "if os.path.exists(dataset_path):\n",
                "    with open(dataset_path, 'r', encoding='utf-8') as f:\n",
                "        data = json.load(f)\n",
                "    print(f\"‚úÖ Dataset loaded: {len(data)} samples\")\n",
                "    print(f\"\\nüìå Sample data:\")\n",
                "    for i, sample in enumerate(data[:3]):\n",
                "        print(f\"   {i+1}. {sample['text'][:60]}... -> {sample.get('sentiment', 'N/A')}\")\n",
                "else:\n",
                "    print(\"‚ùå Dataset not found! Creating sample dataset...\")\n",
                "    # T·∫°o sample dataset\n",
                "    data = [\n",
                "        {\"text\": \"Ph·∫£i v√†o ngay kh√¥ng th√¨ l·ª° c∆° h·ªôi, gi√° ƒëang tƒÉng m·∫°nh!\", \"sentiment\": \"negative\", \"emotion\": \"FOMO\"},\n",
                "        {\"text\": \"T√¥i ƒë√£ ph√¢n t√≠ch k·ªπ chart v√† x√°c ƒë·ªãnh entry point t·ªët\", \"sentiment\": \"positive\", \"emotion\": \"RATIONAL\"},\n",
                "        {\"text\": \"S·ª£ qu√°, gi√° dump m·∫°nh, ph·∫£i c·∫Øt l·ªó th√¥i\", \"sentiment\": \"negative\", \"emotion\": \"FEAR\"},\n",
                "        {\"text\": \"Ti·∫øp t·ª•c tu√¢n th·ªß k·∫ø ho·∫°ch giao d·ªãch ƒë√£ ƒë·∫∑t ra\", \"sentiment\": \"positive\", \"emotion\": \"DISCIPLINE\"},\n",
                "        {\"text\": \"Thua r·ªìi, ph·∫£i g·ª° l·∫°i ngay, all-in leverage x100\", \"sentiment\": \"negative\", \"emotion\": \"REVENGE\"},\n",
                "        {\"text\": \"Ch·ªët l·ªùi theo plan, t·ª∑ l·ªá R:R nh∆∞ d·ª± ki·∫øn\", \"sentiment\": \"positive\", \"emotion\": \"CONFIDENT\"},\n",
                "        {\"text\": \"Th·ªã tr∆∞·ªùng ƒëang sideway, n√™n ch·ªù breakout\", \"sentiment\": \"neutral\", \"emotion\": \"RATIONAL\"},\n",
                "        {\"text\": \"Coin n√†y s·∫Ω x10, all in kh√¥ng c·∫ßn suy nghƒ©!\", \"sentiment\": \"negative\", \"emotion\": \"GREED\"},\n",
                "    ]\n",
                "    print(f\"‚úÖ Created sample dataset: {len(data)} samples\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üöÄ B∆∞·ªõc 5: Train NLP Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import classification_report, accuracy_score\n",
                "from transformers import (\n",
                "    AutoTokenizer, \n",
                "    AutoModelForSequenceClassification,\n",
                "    TrainingArguments,\n",
                "    Trainer,\n",
                "    DataCollatorWithPadding\n",
                ")\n",
                "from datasets import Dataset\n",
                "\n",
                "# Prepare data\n",
                "texts = [d['text'] for d in data]\n",
                "label_map = {label: i for i, label in enumerate(CONFIG['sentiment_labels'])}\n",
                "labels = [label_map.get(d.get('sentiment', 'neutral'), 1) for d in data]\n",
                "\n",
                "print(f\"üìä Label distribution:\")\n",
                "for label, idx in label_map.items():\n",
                "    count = labels.count(idx)\n",
                "    print(f\"   {label}: {count}\")\n",
                "\n",
                "# Split data\n",
                "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
                "    texts, labels, test_size=0.2, random_state=42\n",
                ")\n",
                "\n",
                "print(f\"\\n‚úÖ Train: {len(train_texts)}, Test: {len(test_texts)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load tokenizer & model\n",
                "print(f\"üì¶ Loading model: {CONFIG['base_model']}\")\n",
                "\n",
                "tokenizer = AutoTokenizer.from_pretrained(CONFIG['base_model'])\n",
                "model = AutoModelForSequenceClassification.from_pretrained(\n",
                "    CONFIG['base_model'],\n",
                "    num_labels=len(CONFIG['sentiment_labels'])\n",
                ")\n",
                "\n",
                "print(\"‚úÖ Model loaded!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Tokenize function\n",
                "def tokenize_function(examples):\n",
                "    return tokenizer(\n",
                "        examples['text'],\n",
                "        padding='max_length',\n",
                "        truncation=True,\n",
                "        max_length=CONFIG['max_length']\n",
                "    )\n",
                "\n",
                "# Create datasets\n",
                "train_dataset = Dataset.from_dict({\"text\": train_texts, \"label\": train_labels})\n",
                "test_dataset = Dataset.from_dict({\"text\": test_texts, \"label\": test_labels})\n",
                "\n",
                "# Tokenize\n",
                "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
                "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
                "\n",
                "print(\"‚úÖ Data tokenized!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training arguments\n",
                "training_args = TrainingArguments(\n",
                "    output_dir=\"./results\",\n",
                "    learning_rate=CONFIG['learning_rate'],\n",
                "    per_device_train_batch_size=CONFIG['batch_size'],\n",
                "    per_device_eval_batch_size=CONFIG['batch_size'],\n",
                "    num_train_epochs=CONFIG['epochs'],\n",
                "    weight_decay=0.01,\n",
                "    eval_strategy=\"epoch\",\n",
                "    save_strategy=\"epoch\",\n",
                "    load_best_model_at_end=True,\n",
                "    logging_steps=10,\n",
                "    report_to=\"none\",\n",
                "    fp16=True  # S·ª≠ d·ª•ng mixed precision cho GPU\n",
                ")\n",
                "\n",
                "# Compute metrics\n",
                "def compute_metrics(eval_pred):\n",
                "    predictions, labels = eval_pred\n",
                "    predictions = np.argmax(predictions, axis=1)\n",
                "    return {'accuracy': accuracy_score(labels, predictions)}\n",
                "\n",
                "# Create trainer\n",
                "trainer = Trainer(\n",
                "    model=model,\n",
                "    args=training_args,\n",
                "    train_dataset=train_dataset,\n",
                "    eval_dataset=test_dataset,\n",
                "    tokenizer=tokenizer,\n",
                "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
                "    compute_metrics=compute_metrics\n",
                ")\n",
                "\n",
                "print(\"‚úÖ Trainer created!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üöÄ TRAIN!\n",
                "print(\"=\"*50)\n",
                "print(\"üöÄ Starting training...\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "trainer.train()\n",
                "\n",
                "print(\"\\n‚úÖ Training complete!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate\n",
                "print(\"üìä Evaluating model...\")\n",
                "\n",
                "predictions = trainer.predict(test_dataset)\n",
                "preds = np.argmax(predictions.predictions, axis=1)\n",
                "\n",
                "# Classification report\n",
                "id_to_label = {v: k for k, v in label_map.items()}\n",
                "print(\"\\n\" + classification_report(\n",
                "    test_labels, preds,\n",
                "    target_names=CONFIG['sentiment_labels']\n",
                "))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üíæ B∆∞·ªõc 6: L∆∞u Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# L∆∞u model\n",
                "output_dir = \"./trained_model\"\n",
                "trainer.save_model(output_dir)\n",
                "tokenizer.save_pretrained(output_dir)\n",
                "\n",
                "print(f\"‚úÖ Model saved to {output_dir}\")\n",
                "\n",
                "# Zip ƒë·ªÉ download\n",
                "!zip -r trained_model.zip trained_model/\n",
                "print(\"\\nüì¶ Model zipped: trained_model.zip\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download model v·ªÅ m√°y\n",
                "from google.colab import files\n",
                "files.download('trained_model.zip')\n",
                "\n",
                "print(\"\\n‚úÖ Download complete!\")\n",
                "print(\"üìÅ Gi·∫£i n√©n file v√† copy v√†o: backend/ml/models/finbert_trading_vi/\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üß™ B∆∞·ªõc 7: Test Model (Optional)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test v·ªõi vƒÉn b·∫£n m·ªõi\n",
                "test_texts = [\n",
                "    \"Ph·∫£i mua ngay, gi√° ƒëang tƒÉng m·∫°nh!\",\n",
                "    \"T√¥i ƒë√£ ph√¢n t√≠ch k·ªπ v√† quy·∫øt ƒë·ªãnh v√†o l·ªánh theo plan\",\n",
                "    \"S·ª£ qu√°, b√°n h·∫øt ƒëi th√¥i\",\n",
                "    \"H√¥m nay th·ªã tr∆∞·ªùng sideway, ch·ªù ƒë·ª£i th√™m\"\n",
                "]\n",
                "\n",
                "print(\"üß™ Testing model predictions:\\n\")\n",
                "\n",
                "for text in test_texts:\n",
                "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128)\n",
                "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        outputs = model(**inputs)\n",
                "        probs = torch.softmax(outputs.logits, dim=-1)\n",
                "        pred_idx = torch.argmax(probs).item()\n",
                "        confidence = probs[0][pred_idx].item()\n",
                "    \n",
                "    label = CONFIG['sentiment_labels'][pred_idx]\n",
                "    print(f\"üìù \\\"{text[:40]}...\\\"\")\n",
                "    print(f\"   ‚Üí {label} (confidence: {confidence:.2%})\\n\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## ‚úÖ Ho√†n t·∫•t!\n",
                "\n",
                "B·∫°n ƒë√£ train xong NLP model. C√°c b∆∞·ªõc ti·∫øp theo:\n",
                "\n",
                "1. Download file `trained_model.zip`\n",
                "2. Gi·∫£i n√©n v√† copy v√†o `backend/ml/models/finbert_trading_vi/`\n",
                "3. Ch·∫°y l·∫°i backend ƒë·ªÉ s·ª≠ d·ª•ng model m·ªõi\n",
                "\n",
                "---"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
